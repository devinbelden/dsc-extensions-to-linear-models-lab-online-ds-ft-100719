{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extensions to Linear Models - Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this lab, you'll practice many concepts you have learned so far, from adding interactions and polynomials to your model to AIC and BIC!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "You will be able to:\n",
    "- Build a linear regression model with interactions and polynomial features \n",
    "- Use AIC and BIC to select the best value for the regularization parameter \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all the necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at a baseline boston housing data model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Import the Boston housing dataset \n",
    "- Split the data into target (`y`) and predictors (`X`) -- ensure these both are DataFrames \n",
    "- Scale all the predictors using `scale`. Convert these scaled features into a DataFrame \n",
    "- Build at a baseline model using *scaled variables* as predictors. Use 5-fold cross-validation (set `random_state` to 1) and use the $R^2$ score to evaluate the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24.0</td>\n",
       "      <td>-0.419782</td>\n",
       "      <td>0.284830</td>\n",
       "      <td>-1.287909</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.144217</td>\n",
       "      <td>0.413672</td>\n",
       "      <td>-0.120013</td>\n",
       "      <td>0.140214</td>\n",
       "      <td>-0.982843</td>\n",
       "      <td>-0.666608</td>\n",
       "      <td>-1.459000</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-1.075562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21.6</td>\n",
       "      <td>-0.417339</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-0.593381</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.740262</td>\n",
       "      <td>0.194274</td>\n",
       "      <td>0.367166</td>\n",
       "      <td>0.557160</td>\n",
       "      <td>-0.867883</td>\n",
       "      <td>-0.987329</td>\n",
       "      <td>-0.303094</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-0.492439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34.7</td>\n",
       "      <td>-0.417342</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-0.593381</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.740262</td>\n",
       "      <td>1.282714</td>\n",
       "      <td>-0.265812</td>\n",
       "      <td>0.557160</td>\n",
       "      <td>-0.867883</td>\n",
       "      <td>-0.987329</td>\n",
       "      <td>-0.303094</td>\n",
       "      <td>0.396427</td>\n",
       "      <td>-1.208727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33.4</td>\n",
       "      <td>-0.416750</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-1.306878</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.835284</td>\n",
       "      <td>1.016303</td>\n",
       "      <td>-0.809889</td>\n",
       "      <td>1.077737</td>\n",
       "      <td>-0.752922</td>\n",
       "      <td>-1.106115</td>\n",
       "      <td>0.113032</td>\n",
       "      <td>0.416163</td>\n",
       "      <td>-1.361517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36.2</td>\n",
       "      <td>-0.412482</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-1.306878</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.835284</td>\n",
       "      <td>1.228577</td>\n",
       "      <td>-0.511180</td>\n",
       "      <td>1.077737</td>\n",
       "      <td>-0.752922</td>\n",
       "      <td>-1.106115</td>\n",
       "      <td>0.113032</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-1.026501</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target      CRIM        ZN     INDUS      CHAS       NOX        RM  \\\n",
       "0    24.0 -0.419782  0.284830 -1.287909 -0.272599 -0.144217  0.413672   \n",
       "1    21.6 -0.417339 -0.487722 -0.593381 -0.272599 -0.740262  0.194274   \n",
       "2    34.7 -0.417342 -0.487722 -0.593381 -0.272599 -0.740262  1.282714   \n",
       "3    33.4 -0.416750 -0.487722 -1.306878 -0.272599 -0.835284  1.016303   \n",
       "4    36.2 -0.412482 -0.487722 -1.306878 -0.272599 -0.835284  1.228577   \n",
       "\n",
       "        AGE       DIS       RAD       TAX   PTRATIO         B     LSTAT  \n",
       "0 -0.120013  0.140214 -0.982843 -0.666608 -1.459000  0.441052 -1.075562  \n",
       "1  0.367166  0.557160 -0.867883 -0.987329 -0.303094  0.441052 -0.492439  \n",
       "2 -0.265812  0.557160 -0.867883 -0.987329 -0.303094  0.396427 -1.208727  \n",
       "3 -0.809889  1.077737 -0.752922 -1.106115  0.113032  0.416163 -1.361517  \n",
       "4 -0.511180  1.077737 -0.752922 -1.106115  0.113032  0.441052 -1.026501  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "y = pd.DataFrame(load_boston().target, columns=['target'])\n",
    "X = pd.DataFrame(load_boston().data, columns=load_boston().feature_names)\n",
    "\n",
    "X_scaled = scale(X)\n",
    "X_scaled = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "\n",
    "boston = pd.concat([y, X_scaled], axis=1)\n",
    "boston.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7176778617934925"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linreg = LinearRegression()\n",
    "\n",
    "crossvalidation = KFold(n_splits=5, random_state=1, shuffle=True)\n",
    "baseline = np.mean(cross_val_score(linreg, X_scaled, y, scoring='r2', cv=crossvalidation))\n",
    "baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Include interactions\n",
    "\n",
    "Look at all the possible combinations of variables for interactions by adding interactions one by one to the baseline model. Next, evaluate that model using 5-fold cross-validation and store the $R^2$ to compare it with the baseline model.\n",
    "\n",
    "Print the 7 most important interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 7 Interactions: [('RM', 'LSTAT', 0.783), ('RM', 'TAX', 0.775), ('RM', 'RAD', 0.77), ('RM', 'PTRATIO', 0.764), ('INDUS', 'RM', 0.757), ('NOX', 'RM', 0.746), ('RM', 'AGE', 0.742)]\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "from itertools import combinations\n",
    "\n",
    "combs = list(combinations(X_scaled.columns, 2))\n",
    "interactions = []\n",
    "data = X_scaled.copy()\n",
    "for comb in combs:\n",
    "    data['interaction'] = data[comb[0]] * data[comb[1]]\n",
    "    score = np.mean(cross_val_score(linreg, data, y, scoring='r2', cv=crossvalidation))\n",
    "    if score > baseline:\n",
    "        interactions.append((comb[0], comb[1], round(score, 3)))\n",
    "\n",
    "print(\"Top 7 Interactions: %s\" %sorted(interactions, key=lambda x: x[2], reverse=True)[:7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write code to include the 7 most important interactions in your data set by adding 7 columns. Name the columns \"var1_var2\" with var1 and var2 the two variables in the interaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX',\n",
       "       'PTRATIO', 'B', 'LSTAT', 'RM_LSTAT', 'RM_TAX', 'RM_RAD', 'RM_PTRATIO',\n",
       "       'INDUS_RM', 'NOX_RM', 'RM_AGE'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "df_inter = X_scaled.copy()\n",
    "ls_interactions = sorted(interactions, key=lambda x: x[2], reverse=True)[:7]\n",
    "for inter in ls_interactions:\n",
    "    df_inter[inter[0] + '_' + inter[1]] = X[inter[0]] * X[inter[1]]\n",
    "df_inter.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Include polynomials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try polynomials of degrees 2, 3, and 4 for each variable, in a similar way you did for interactions (by looking at your baseline model and seeing how $R^2$ increases). Do understand that when going for a polynomial of 4, the particular column is raised to the power of 2 and 3 as well in other terms. We only want to include \"pure\" polynomials, so make sure no interactions are included. We want the result to return a list that contain tuples of the form:\n",
    "\n",
    "`(var_name, degree, R2)`, so eg. `('DIS', 3, 0.732)` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Polynomials: [('RM', 4, 0.8), ('RM', 2, 0.782), ('LSTAT', 4, 0.782), ('RM', 3, 0.781), ('LSTAT', 3, 0.774), ('LSTAT', 2, 0.772), ('DIS', 3, 0.737), ('DIS', 2, 0.732), ('DIS', 4, 0.731), ('TAX', 4, 0.724)]\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "polynomials = []\n",
    "for col in X.columns:\n",
    "    for degree in [2, 3, 4]:\n",
    "        data = X_scaled.copy()\n",
    "        poly = PolynomialFeatures(degree, include_bias=False)\n",
    "        X_transformed = poly.fit_transform(X[[col]])\n",
    "        data = pd.concat([data.drop(col, axis=1), pd.DataFrame(X_transformed)], axis=1)\n",
    "        score = np.mean(cross_val_score(linreg, data, y, scoring='r2', cv=crossvalidation))\n",
    "        if score > baseline:\n",
    "            polynomials.append((col, degree, round(score, 3)))\n",
    "        \n",
    "print(\"Top 10 Polynomials: %s\" %sorted(polynomials, key=lambda poly: poly[2], reverse=True)[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each variable, print out the maximum R2 possible when including Polynomials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZN</td>\n",
       "      <td>2</td>\n",
       "      <td>0.720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZN</td>\n",
       "      <td>3</td>\n",
       "      <td>0.723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ZN</td>\n",
       "      <td>4</td>\n",
       "      <td>0.720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INDUS</td>\n",
       "      <td>2</td>\n",
       "      <td>0.723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>INDUS</td>\n",
       "      <td>3</td>\n",
       "      <td>0.723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>INDUS</td>\n",
       "      <td>4</td>\n",
       "      <td>0.723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NOX</td>\n",
       "      <td>2</td>\n",
       "      <td>0.718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NOX</td>\n",
       "      <td>3</td>\n",
       "      <td>0.718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NOX</td>\n",
       "      <td>4</td>\n",
       "      <td>0.721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RM</td>\n",
       "      <td>2</td>\n",
       "      <td>0.782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RM</td>\n",
       "      <td>3</td>\n",
       "      <td>0.781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RM</td>\n",
       "      <td>4</td>\n",
       "      <td>0.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>AGE</td>\n",
       "      <td>2</td>\n",
       "      <td>0.721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>AGE</td>\n",
       "      <td>3</td>\n",
       "      <td>0.722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>AGE</td>\n",
       "      <td>4</td>\n",
       "      <td>0.722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>DIS</td>\n",
       "      <td>2</td>\n",
       "      <td>0.732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>DIS</td>\n",
       "      <td>3</td>\n",
       "      <td>0.737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>DIS</td>\n",
       "      <td>4</td>\n",
       "      <td>0.731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>RAD</td>\n",
       "      <td>4</td>\n",
       "      <td>0.720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>TAX</td>\n",
       "      <td>2</td>\n",
       "      <td>0.719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>TAX</td>\n",
       "      <td>3</td>\n",
       "      <td>0.721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>TAX</td>\n",
       "      <td>4</td>\n",
       "      <td>0.724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>PTRATIO</td>\n",
       "      <td>2</td>\n",
       "      <td>0.721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>PTRATIO</td>\n",
       "      <td>3</td>\n",
       "      <td>0.719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>B</td>\n",
       "      <td>2</td>\n",
       "      <td>0.720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>B</td>\n",
       "      <td>3</td>\n",
       "      <td>0.719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>B</td>\n",
       "      <td>4</td>\n",
       "      <td>0.718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>LSTAT</td>\n",
       "      <td>2</td>\n",
       "      <td>0.772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>LSTAT</td>\n",
       "      <td>3</td>\n",
       "      <td>0.774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>LSTAT</td>\n",
       "      <td>4</td>\n",
       "      <td>0.782</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0  1      2\n",
       "0        ZN  2  0.720\n",
       "1        ZN  3  0.723\n",
       "2        ZN  4  0.720\n",
       "3     INDUS  2  0.723\n",
       "4     INDUS  3  0.723\n",
       "5     INDUS  4  0.723\n",
       "6       NOX  2  0.718\n",
       "7       NOX  3  0.718\n",
       "8       NOX  4  0.721\n",
       "9        RM  2  0.782\n",
       "10       RM  3  0.781\n",
       "11       RM  4  0.800\n",
       "12      AGE  2  0.721\n",
       "13      AGE  3  0.722\n",
       "14      AGE  4  0.722\n",
       "15      DIS  2  0.732\n",
       "16      DIS  3  0.737\n",
       "17      DIS  4  0.731\n",
       "18      RAD  4  0.720\n",
       "19      TAX  2  0.719\n",
       "20      TAX  3  0.721\n",
       "21      TAX  4  0.724\n",
       "22  PTRATIO  2  0.721\n",
       "23  PTRATIO  3  0.719\n",
       "24        B  2  0.720\n",
       "25        B  3  0.719\n",
       "26        B  4  0.718\n",
       "27    LSTAT  2  0.772\n",
       "28    LSTAT  3  0.774\n",
       "29    LSTAT  4  0.782"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polynom = pd.DataFrame(polynomials)\n",
    "polynom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "ZN         0.723\n",
       "INDUS      0.723\n",
       "NOX        0.721\n",
       "RM         0.800\n",
       "AGE        0.722\n",
       "DIS        0.737\n",
       "RAD        0.720\n",
       "TAX        0.724\n",
       "PTRATIO    0.721\n",
       "B          0.720\n",
       "LSTAT      0.782\n",
       "Name: 2, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "\n",
    "polynom.groupby([0], sort=False)[2].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which two variables seem to benefit most from adding polynomial terms?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add Polynomials for the two features that seem to benefit the most, as in have the best R squared compared to the baseline model. For each of the two features, raise to the Polynomial that generates the best result. Make sure to start from the data set `df_inter` so the final data set has both interactions and polynomials in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "for col in ['RM', 'LSTAT']:\n",
    "    poly = PolynomialFeatures(4, include_bias=False)\n",
    "    X_transformed = poly.fit_transform(X[[col]])\n",
    "    colnames= [col, col + '_' + '2',  col + '_' + '3', col + '_' + '4']\n",
    "    X_transformed_df = pd.DataFrame(X_transformed, columns=colnames)\n",
    "    X_transformed_df.drop([col, col + '_' + '2',  col + '_' + '3'], axis=1, inplace=True)\n",
    "    df_inter.drop([col], axis=1, inplace=True)\n",
    "    df_inter = pd.concat([df_inter, X_transformed_df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out your final data set and make sure that your interaction terms as well as your polynomial terms are included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'AGE', 'DIS', 'RAD', 'TAX',\n",
       "       'PTRATIO', 'B', 'RM_LSTAT', 'RM_TAX', 'RM_RAD', 'RM_PTRATIO',\n",
       "       'INDUS_RM', 'NOX_RM', 'RM_AGE', 'RM_4', 'LSTAT_4'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_inter.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>RM_LSTAT</th>\n",
       "      <th>RM_TAX</th>\n",
       "      <th>RM_RAD</th>\n",
       "      <th>RM_PTRATIO</th>\n",
       "      <th>INDUS_RM</th>\n",
       "      <th>NOX_RM</th>\n",
       "      <th>RM_AGE</th>\n",
       "      <th>RM_4</th>\n",
       "      <th>LSTAT_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CRIM</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.200469</td>\n",
       "      <td>0.406583</td>\n",
       "      <td>-0.055892</td>\n",
       "      <td>0.420972</td>\n",
       "      <td>0.352734</td>\n",
       "      <td>-0.379670</td>\n",
       "      <td>0.625505</td>\n",
       "      <td>0.582764</td>\n",
       "      <td>0.289946</td>\n",
       "      <td>-0.385064</td>\n",
       "      <td>0.450529</td>\n",
       "      <td>0.527826</td>\n",
       "      <td>0.591175</td>\n",
       "      <td>0.070356</td>\n",
       "      <td>0.377761</td>\n",
       "      <td>0.297827</td>\n",
       "      <td>0.283140</td>\n",
       "      <td>-0.172931</td>\n",
       "      <td>0.398979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZN</th>\n",
       "      <td>-0.200469</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.533828</td>\n",
       "      <td>-0.042697</td>\n",
       "      <td>-0.516604</td>\n",
       "      <td>-0.569537</td>\n",
       "      <td>0.664408</td>\n",
       "      <td>-0.311948</td>\n",
       "      <td>-0.314563</td>\n",
       "      <td>-0.391679</td>\n",
       "      <td>0.175520</td>\n",
       "      <td>-0.419774</td>\n",
       "      <td>-0.254988</td>\n",
       "      <td>-0.295961</td>\n",
       "      <td>-0.114018</td>\n",
       "      <td>-0.523880</td>\n",
       "      <td>-0.375509</td>\n",
       "      <td>-0.517755</td>\n",
       "      <td>0.284471</td>\n",
       "      <td>-0.192788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INDUS</th>\n",
       "      <td>0.406583</td>\n",
       "      <td>-0.533828</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.062938</td>\n",
       "      <td>0.763651</td>\n",
       "      <td>0.644779</td>\n",
       "      <td>-0.708027</td>\n",
       "      <td>0.595129</td>\n",
       "      <td>0.720760</td>\n",
       "      <td>0.383248</td>\n",
       "      <td>-0.356977</td>\n",
       "      <td>0.606946</td>\n",
       "      <td>0.648660</td>\n",
       "      <td>0.569430</td>\n",
       "      <td>0.031025</td>\n",
       "      <td>0.978115</td>\n",
       "      <td>0.558953</td>\n",
       "      <td>0.541907</td>\n",
       "      <td>-0.351961</td>\n",
       "      <td>0.365378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHAS</th>\n",
       "      <td>-0.055892</td>\n",
       "      <td>-0.042697</td>\n",
       "      <td>0.062938</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.091203</td>\n",
       "      <td>0.086518</td>\n",
       "      <td>-0.099176</td>\n",
       "      <td>-0.007368</td>\n",
       "      <td>-0.035587</td>\n",
       "      <td>-0.121515</td>\n",
       "      <td>0.048788</td>\n",
       "      <td>-0.052988</td>\n",
       "      <td>-0.003459</td>\n",
       "      <td>0.012112</td>\n",
       "      <td>-0.029136</td>\n",
       "      <td>0.091764</td>\n",
       "      <td>0.142861</td>\n",
       "      <td>0.114610</td>\n",
       "      <td>0.109469</td>\n",
       "      <td>-0.047186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOX</th>\n",
       "      <td>0.420972</td>\n",
       "      <td>-0.516604</td>\n",
       "      <td>0.763651</td>\n",
       "      <td>0.091203</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.731470</td>\n",
       "      <td>-0.769230</td>\n",
       "      <td>0.611441</td>\n",
       "      <td>0.668023</td>\n",
       "      <td>0.188933</td>\n",
       "      <td>-0.380051</td>\n",
       "      <td>0.603520</td>\n",
       "      <td>0.610558</td>\n",
       "      <td>0.591331</td>\n",
       "      <td>-0.073346</td>\n",
       "      <td>0.737006</td>\n",
       "      <td>0.836015</td>\n",
       "      <td>0.655517</td>\n",
       "      <td>-0.240575</td>\n",
       "      <td>0.374135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGE</th>\n",
       "      <td>0.352734</td>\n",
       "      <td>-0.569537</td>\n",
       "      <td>0.644779</td>\n",
       "      <td>0.086518</td>\n",
       "      <td>0.731470</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.747881</td>\n",
       "      <td>0.456022</td>\n",
       "      <td>0.506456</td>\n",
       "      <td>0.261515</td>\n",
       "      <td>-0.273534</td>\n",
       "      <td>0.627428</td>\n",
       "      <td>0.457527</td>\n",
       "      <td>0.437518</td>\n",
       "      <td>0.033146</td>\n",
       "      <td>0.629760</td>\n",
       "      <td>0.615994</td>\n",
       "      <td>0.950845</td>\n",
       "      <td>-0.182931</td>\n",
       "      <td>0.351622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DIS</th>\n",
       "      <td>-0.379670</td>\n",
       "      <td>0.664408</td>\n",
       "      <td>-0.708027</td>\n",
       "      <td>-0.099176</td>\n",
       "      <td>-0.769230</td>\n",
       "      <td>-0.747881</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.494588</td>\n",
       "      <td>-0.534432</td>\n",
       "      <td>-0.232471</td>\n",
       "      <td>0.291512</td>\n",
       "      <td>-0.509215</td>\n",
       "      <td>-0.489037</td>\n",
       "      <td>-0.475902</td>\n",
       "      <td>-0.033548</td>\n",
       "      <td>-0.693855</td>\n",
       "      <td>-0.665687</td>\n",
       "      <td>-0.705330</td>\n",
       "      <td>0.138342</td>\n",
       "      <td>-0.321437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RAD</th>\n",
       "      <td>0.625505</td>\n",
       "      <td>-0.311948</td>\n",
       "      <td>0.595129</td>\n",
       "      <td>-0.007368</td>\n",
       "      <td>0.611441</td>\n",
       "      <td>0.456022</td>\n",
       "      <td>-0.494588</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.910228</td>\n",
       "      <td>0.464741</td>\n",
       "      <td>-0.444413</td>\n",
       "      <td>0.514001</td>\n",
       "      <td>0.879977</td>\n",
       "      <td>0.984215</td>\n",
       "      <td>0.241418</td>\n",
       "      <td>0.586922</td>\n",
       "      <td>0.505626</td>\n",
       "      <td>0.397985</td>\n",
       "      <td>-0.170864</td>\n",
       "      <td>0.333954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TAX</th>\n",
       "      <td>0.582764</td>\n",
       "      <td>-0.314563</td>\n",
       "      <td>0.720760</td>\n",
       "      <td>-0.035587</td>\n",
       "      <td>0.668023</td>\n",
       "      <td>0.506456</td>\n",
       "      <td>-0.534432</td>\n",
       "      <td>0.910228</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.460853</td>\n",
       "      <td>-0.441808</td>\n",
       "      <td>0.560237</td>\n",
       "      <td>0.953916</td>\n",
       "      <td>0.888006</td>\n",
       "      <td>0.171754</td>\n",
       "      <td>0.702160</td>\n",
       "      <td>0.515952</td>\n",
       "      <td>0.423844</td>\n",
       "      <td>-0.254639</td>\n",
       "      <td>0.357264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PTRATIO</th>\n",
       "      <td>0.289946</td>\n",
       "      <td>-0.391679</td>\n",
       "      <td>0.383248</td>\n",
       "      <td>-0.121515</td>\n",
       "      <td>0.188933</td>\n",
       "      <td>0.261515</td>\n",
       "      <td>-0.232471</td>\n",
       "      <td>0.464741</td>\n",
       "      <td>0.460853</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.177383</td>\n",
       "      <td>0.378828</td>\n",
       "      <td>0.393461</td>\n",
       "      <td>0.441102</td>\n",
       "      <td>0.623993</td>\n",
       "      <td>0.360723</td>\n",
       "      <td>0.016519</td>\n",
       "      <td>0.170821</td>\n",
       "      <td>-0.370661</td>\n",
       "      <td>0.187545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>-0.385064</td>\n",
       "      <td>0.175520</td>\n",
       "      <td>-0.356977</td>\n",
       "      <td>0.048788</td>\n",
       "      <td>-0.380051</td>\n",
       "      <td>-0.273534</td>\n",
       "      <td>0.291512</td>\n",
       "      <td>-0.444413</td>\n",
       "      <td>-0.441808</td>\n",
       "      <td>-0.177383</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.402309</td>\n",
       "      <td>-0.426156</td>\n",
       "      <td>-0.439794</td>\n",
       "      <td>-0.058012</td>\n",
       "      <td>-0.352011</td>\n",
       "      <td>-0.317218</td>\n",
       "      <td>-0.239581</td>\n",
       "      <td>0.119207</td>\n",
       "      <td>-0.256493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RM_LSTAT</th>\n",
       "      <td>0.450529</td>\n",
       "      <td>-0.419774</td>\n",
       "      <td>0.606946</td>\n",
       "      <td>-0.052988</td>\n",
       "      <td>0.603520</td>\n",
       "      <td>0.627428</td>\n",
       "      <td>-0.509215</td>\n",
       "      <td>0.514001</td>\n",
       "      <td>0.560237</td>\n",
       "      <td>0.378828</td>\n",
       "      <td>-0.402309</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.456434</td>\n",
       "      <td>0.476783</td>\n",
       "      <td>-0.059234</td>\n",
       "      <td>0.547248</td>\n",
       "      <td>0.346079</td>\n",
       "      <td>0.492414</td>\n",
       "      <td>-0.464402</td>\n",
       "      <td>0.709149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RM_TAX</th>\n",
       "      <td>0.527826</td>\n",
       "      <td>-0.254988</td>\n",
       "      <td>0.648660</td>\n",
       "      <td>-0.003459</td>\n",
       "      <td>0.610558</td>\n",
       "      <td>0.457527</td>\n",
       "      <td>-0.489037</td>\n",
       "      <td>0.879977</td>\n",
       "      <td>0.953916</td>\n",
       "      <td>0.393461</td>\n",
       "      <td>-0.426156</td>\n",
       "      <td>0.456434</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.908290</td>\n",
       "      <td>0.346407</td>\n",
       "      <td>0.689432</td>\n",
       "      <td>0.622645</td>\n",
       "      <td>0.463106</td>\n",
       "      <td>-0.007004</td>\n",
       "      <td>0.214666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RM_RAD</th>\n",
       "      <td>0.591175</td>\n",
       "      <td>-0.295961</td>\n",
       "      <td>0.569430</td>\n",
       "      <td>0.012112</td>\n",
       "      <td>0.591331</td>\n",
       "      <td>0.437518</td>\n",
       "      <td>-0.475902</td>\n",
       "      <td>0.984215</td>\n",
       "      <td>0.888006</td>\n",
       "      <td>0.441102</td>\n",
       "      <td>-0.439794</td>\n",
       "      <td>0.476783</td>\n",
       "      <td>0.908290</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.339246</td>\n",
       "      <td>0.593877</td>\n",
       "      <td>0.568959</td>\n",
       "      <td>0.425353</td>\n",
       "      <td>-0.055909</td>\n",
       "      <td>0.255928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RM_PTRATIO</th>\n",
       "      <td>0.070356</td>\n",
       "      <td>-0.114018</td>\n",
       "      <td>0.031025</td>\n",
       "      <td>-0.029136</td>\n",
       "      <td>-0.073346</td>\n",
       "      <td>0.033146</td>\n",
       "      <td>-0.033548</td>\n",
       "      <td>0.241418</td>\n",
       "      <td>0.171754</td>\n",
       "      <td>0.623993</td>\n",
       "      <td>-0.058012</td>\n",
       "      <td>-0.059234</td>\n",
       "      <td>0.346407</td>\n",
       "      <td>0.339246</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.154233</td>\n",
       "      <td>0.233600</td>\n",
       "      <td>0.195857</td>\n",
       "      <td>0.437631</td>\n",
       "      <td>-0.216203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INDUS_RM</th>\n",
       "      <td>0.377761</td>\n",
       "      <td>-0.523880</td>\n",
       "      <td>0.978115</td>\n",
       "      <td>0.091764</td>\n",
       "      <td>0.737006</td>\n",
       "      <td>0.629760</td>\n",
       "      <td>-0.693855</td>\n",
       "      <td>0.586922</td>\n",
       "      <td>0.702160</td>\n",
       "      <td>0.360723</td>\n",
       "      <td>-0.352011</td>\n",
       "      <td>0.547248</td>\n",
       "      <td>0.689432</td>\n",
       "      <td>0.593877</td>\n",
       "      <td>0.154233</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.636459</td>\n",
       "      <td>0.584608</td>\n",
       "      <td>-0.207017</td>\n",
       "      <td>0.268436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOX_RM</th>\n",
       "      <td>0.297827</td>\n",
       "      <td>-0.375509</td>\n",
       "      <td>0.558953</td>\n",
       "      <td>0.142861</td>\n",
       "      <td>0.836015</td>\n",
       "      <td>0.615994</td>\n",
       "      <td>-0.665687</td>\n",
       "      <td>0.505626</td>\n",
       "      <td>0.515952</td>\n",
       "      <td>0.016519</td>\n",
       "      <td>-0.317218</td>\n",
       "      <td>0.346079</td>\n",
       "      <td>0.622645</td>\n",
       "      <td>0.568959</td>\n",
       "      <td>0.233600</td>\n",
       "      <td>0.636459</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.714506</td>\n",
       "      <td>0.287166</td>\n",
       "      <td>0.105047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RM_AGE</th>\n",
       "      <td>0.283140</td>\n",
       "      <td>-0.517755</td>\n",
       "      <td>0.541907</td>\n",
       "      <td>0.114610</td>\n",
       "      <td>0.655517</td>\n",
       "      <td>0.950845</td>\n",
       "      <td>-0.705330</td>\n",
       "      <td>0.397985</td>\n",
       "      <td>0.423844</td>\n",
       "      <td>0.170821</td>\n",
       "      <td>-0.239581</td>\n",
       "      <td>0.492414</td>\n",
       "      <td>0.463106</td>\n",
       "      <td>0.425353</td>\n",
       "      <td>0.195857</td>\n",
       "      <td>0.584608</td>\n",
       "      <td>0.714506</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.092603</td>\n",
       "      <td>0.198674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RM_4</th>\n",
       "      <td>-0.172931</td>\n",
       "      <td>0.284471</td>\n",
       "      <td>-0.351961</td>\n",
       "      <td>0.109469</td>\n",
       "      <td>-0.240575</td>\n",
       "      <td>-0.182931</td>\n",
       "      <td>0.138342</td>\n",
       "      <td>-0.170864</td>\n",
       "      <td>-0.254639</td>\n",
       "      <td>-0.370661</td>\n",
       "      <td>0.119207</td>\n",
       "      <td>-0.464402</td>\n",
       "      <td>-0.007004</td>\n",
       "      <td>-0.055909</td>\n",
       "      <td>0.437631</td>\n",
       "      <td>-0.207017</td>\n",
       "      <td>0.287166</td>\n",
       "      <td>0.092603</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.334257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTAT_4</th>\n",
       "      <td>0.398979</td>\n",
       "      <td>-0.192788</td>\n",
       "      <td>0.365378</td>\n",
       "      <td>-0.047186</td>\n",
       "      <td>0.374135</td>\n",
       "      <td>0.351622</td>\n",
       "      <td>-0.321437</td>\n",
       "      <td>0.333954</td>\n",
       "      <td>0.357264</td>\n",
       "      <td>0.187545</td>\n",
       "      <td>-0.256493</td>\n",
       "      <td>0.709149</td>\n",
       "      <td>0.214666</td>\n",
       "      <td>0.255928</td>\n",
       "      <td>-0.216203</td>\n",
       "      <td>0.268436</td>\n",
       "      <td>0.105047</td>\n",
       "      <td>0.198674</td>\n",
       "      <td>-0.334257</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                CRIM        ZN     INDUS      CHAS       NOX       AGE  \\\n",
       "CRIM        1.000000 -0.200469  0.406583 -0.055892  0.420972  0.352734   \n",
       "ZN         -0.200469  1.000000 -0.533828 -0.042697 -0.516604 -0.569537   \n",
       "INDUS       0.406583 -0.533828  1.000000  0.062938  0.763651  0.644779   \n",
       "CHAS       -0.055892 -0.042697  0.062938  1.000000  0.091203  0.086518   \n",
       "NOX         0.420972 -0.516604  0.763651  0.091203  1.000000  0.731470   \n",
       "AGE         0.352734 -0.569537  0.644779  0.086518  0.731470  1.000000   \n",
       "DIS        -0.379670  0.664408 -0.708027 -0.099176 -0.769230 -0.747881   \n",
       "RAD         0.625505 -0.311948  0.595129 -0.007368  0.611441  0.456022   \n",
       "TAX         0.582764 -0.314563  0.720760 -0.035587  0.668023  0.506456   \n",
       "PTRATIO     0.289946 -0.391679  0.383248 -0.121515  0.188933  0.261515   \n",
       "B          -0.385064  0.175520 -0.356977  0.048788 -0.380051 -0.273534   \n",
       "RM_LSTAT    0.450529 -0.419774  0.606946 -0.052988  0.603520  0.627428   \n",
       "RM_TAX      0.527826 -0.254988  0.648660 -0.003459  0.610558  0.457527   \n",
       "RM_RAD      0.591175 -0.295961  0.569430  0.012112  0.591331  0.437518   \n",
       "RM_PTRATIO  0.070356 -0.114018  0.031025 -0.029136 -0.073346  0.033146   \n",
       "INDUS_RM    0.377761 -0.523880  0.978115  0.091764  0.737006  0.629760   \n",
       "NOX_RM      0.297827 -0.375509  0.558953  0.142861  0.836015  0.615994   \n",
       "RM_AGE      0.283140 -0.517755  0.541907  0.114610  0.655517  0.950845   \n",
       "RM_4       -0.172931  0.284471 -0.351961  0.109469 -0.240575 -0.182931   \n",
       "LSTAT_4     0.398979 -0.192788  0.365378 -0.047186  0.374135  0.351622   \n",
       "\n",
       "                 DIS       RAD       TAX   PTRATIO         B  RM_LSTAT  \\\n",
       "CRIM       -0.379670  0.625505  0.582764  0.289946 -0.385064  0.450529   \n",
       "ZN          0.664408 -0.311948 -0.314563 -0.391679  0.175520 -0.419774   \n",
       "INDUS      -0.708027  0.595129  0.720760  0.383248 -0.356977  0.606946   \n",
       "CHAS       -0.099176 -0.007368 -0.035587 -0.121515  0.048788 -0.052988   \n",
       "NOX        -0.769230  0.611441  0.668023  0.188933 -0.380051  0.603520   \n",
       "AGE        -0.747881  0.456022  0.506456  0.261515 -0.273534  0.627428   \n",
       "DIS         1.000000 -0.494588 -0.534432 -0.232471  0.291512 -0.509215   \n",
       "RAD        -0.494588  1.000000  0.910228  0.464741 -0.444413  0.514001   \n",
       "TAX        -0.534432  0.910228  1.000000  0.460853 -0.441808  0.560237   \n",
       "PTRATIO    -0.232471  0.464741  0.460853  1.000000 -0.177383  0.378828   \n",
       "B           0.291512 -0.444413 -0.441808 -0.177383  1.000000 -0.402309   \n",
       "RM_LSTAT   -0.509215  0.514001  0.560237  0.378828 -0.402309  1.000000   \n",
       "RM_TAX     -0.489037  0.879977  0.953916  0.393461 -0.426156  0.456434   \n",
       "RM_RAD     -0.475902  0.984215  0.888006  0.441102 -0.439794  0.476783   \n",
       "RM_PTRATIO -0.033548  0.241418  0.171754  0.623993 -0.058012 -0.059234   \n",
       "INDUS_RM   -0.693855  0.586922  0.702160  0.360723 -0.352011  0.547248   \n",
       "NOX_RM     -0.665687  0.505626  0.515952  0.016519 -0.317218  0.346079   \n",
       "RM_AGE     -0.705330  0.397985  0.423844  0.170821 -0.239581  0.492414   \n",
       "RM_4        0.138342 -0.170864 -0.254639 -0.370661  0.119207 -0.464402   \n",
       "LSTAT_4    -0.321437  0.333954  0.357264  0.187545 -0.256493  0.709149   \n",
       "\n",
       "              RM_TAX    RM_RAD  RM_PTRATIO  INDUS_RM    NOX_RM    RM_AGE  \\\n",
       "CRIM        0.527826  0.591175    0.070356  0.377761  0.297827  0.283140   \n",
       "ZN         -0.254988 -0.295961   -0.114018 -0.523880 -0.375509 -0.517755   \n",
       "INDUS       0.648660  0.569430    0.031025  0.978115  0.558953  0.541907   \n",
       "CHAS       -0.003459  0.012112   -0.029136  0.091764  0.142861  0.114610   \n",
       "NOX         0.610558  0.591331   -0.073346  0.737006  0.836015  0.655517   \n",
       "AGE         0.457527  0.437518    0.033146  0.629760  0.615994  0.950845   \n",
       "DIS        -0.489037 -0.475902   -0.033548 -0.693855 -0.665687 -0.705330   \n",
       "RAD         0.879977  0.984215    0.241418  0.586922  0.505626  0.397985   \n",
       "TAX         0.953916  0.888006    0.171754  0.702160  0.515952  0.423844   \n",
       "PTRATIO     0.393461  0.441102    0.623993  0.360723  0.016519  0.170821   \n",
       "B          -0.426156 -0.439794   -0.058012 -0.352011 -0.317218 -0.239581   \n",
       "RM_LSTAT    0.456434  0.476783   -0.059234  0.547248  0.346079  0.492414   \n",
       "RM_TAX      1.000000  0.908290    0.346407  0.689432  0.622645  0.463106   \n",
       "RM_RAD      0.908290  1.000000    0.339246  0.593877  0.568959  0.425353   \n",
       "RM_PTRATIO  0.346407  0.339246    1.000000  0.154233  0.233600  0.195857   \n",
       "INDUS_RM    0.689432  0.593877    0.154233  1.000000  0.636459  0.584608   \n",
       "NOX_RM      0.622645  0.568959    0.233600  0.636459  1.000000  0.714506   \n",
       "RM_AGE      0.463106  0.425353    0.195857  0.584608  0.714506  1.000000   \n",
       "RM_4       -0.007004 -0.055909    0.437631 -0.207017  0.287166  0.092603   \n",
       "LSTAT_4     0.214666  0.255928   -0.216203  0.268436  0.105047  0.198674   \n",
       "\n",
       "                RM_4   LSTAT_4  \n",
       "CRIM       -0.172931  0.398979  \n",
       "ZN          0.284471 -0.192788  \n",
       "INDUS      -0.351961  0.365378  \n",
       "CHAS        0.109469 -0.047186  \n",
       "NOX        -0.240575  0.374135  \n",
       "AGE        -0.182931  0.351622  \n",
       "DIS         0.138342 -0.321437  \n",
       "RAD        -0.170864  0.333954  \n",
       "TAX        -0.254639  0.357264  \n",
       "PTRATIO    -0.370661  0.187545  \n",
       "B           0.119207 -0.256493  \n",
       "RM_LSTAT   -0.464402  0.709149  \n",
       "RM_TAX     -0.007004  0.214666  \n",
       "RM_RAD     -0.055909  0.255928  \n",
       "RM_PTRATIO  0.437631 -0.216203  \n",
       "INDUS_RM   -0.207017  0.268436  \n",
       "NOX_RM      0.287166  0.105047  \n",
       "RM_AGE      0.092603  0.198674  \n",
       "RM_4        1.000000 -0.334257  \n",
       "LSTAT_4    -0.334257  1.000000  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_inter.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full model R-squared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out the R-squared of the full model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.786578288030478"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "np.mean(cross_val_score(linreg, df_inter, y, scoring='r2', cv=crossvalidation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the best Lasso regularization parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You learned that when using Lasso regularization, your coefficients shrink to 0 when using a higher regularization parameter. Now the question is which value we should choose for the regularization parameter. \n",
    "\n",
    "This is where the AIC and BIC come in handy! We'll use both criteria in what follows and perform cross-validation to select an optimal value of the regularization parameter $alpha$ of the Lasso estimator.\n",
    "\n",
    "Read the page here: https://scikit-learn.org/stable/auto_examples/linear_model/plot_lasso_model_selection.html and create a similar plot as the first one listed on the page. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LassoCV, LassoLarsCV, LassoLarsIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x239a4f0f940>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Your code here \n",
    "model_aic = LassoLarsIC(criterion='aic')\n",
    "model_aic.fit(df_inter, y)\n",
    "alpha_aic_ = model_aic.alpha_\n",
    "\n",
    "model_bic = LassoLarsIC(criterion='bic')\n",
    "model_bic.fit(df_inter, y)\n",
    "alpha_bic_ = model_bic.alpha_\n",
    "\n",
    "def plot_ic_criterion(model, name, color):\n",
    "    alpha_ = model.alpha_\n",
    "    alphas_ = model.alphas_\n",
    "    criterion_ = model.criterion_\n",
    "    plt.plot(-np.log10(alphas_), criterion_, '--', color=color,\n",
    "             linewidth=2, label='%s criterion' % name)\n",
    "    plt.axvline(-np.log10(alpha_), color=color, linewidth=2,\n",
    "                label='alpha: %s estimate' % name)\n",
    "    plt.xlabel('-log(alpha)')\n",
    "    plt.ylabel('criterion')\n",
    "    \n",
    "plt.figure(figsize=(8,5))\n",
    "plot_ic_criterion(model_aic, 'aic', 'red')\n",
    "plot_ic_criterion(model_bic, 'bic', 'blue')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze the final result\n",
    "\n",
    "Finally, use the best value for the regularization parameter according to AIC and BIC, and compare R-squared and MSE using train-test split. Compare with the baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_squared_log_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training R2: 0.7168057552393374\n",
      "Test R2: 0.7789410172622857\n",
      "Training MSE: 22.477983821877896\n",
      "Test MSE: 21.897765396049497\n"
     ]
    }
   ],
   "source": [
    "# Split X_scaled and y into training and test sets\n",
    "# Set random_state to 1\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, random_state=1)\n",
    "\n",
    "# Code for baseline model\n",
    "linreg_all = LinearRegression()\n",
    "linreg_all.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Print R2 and MSE\n",
    "print(\"Training R2:\", linreg_all.score(X_train, y_train))\n",
    "print(\"Test R2:\", linreg_all.score(X_test, y_test))\n",
    "print(\"Training MSE:\", mean_squared_error(y_train, linreg_all.predict(X_train)))\n",
    "print(\"Test MSE:\", mean_squared_error(y_test, linreg_all.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training R2: 0.8043961250137526\n",
      "Test R2: 0.8567157800315184\n",
      "Training MSE: 15.525671226664127\n",
      "Test MSE: 14.193516114875631\n"
     ]
    }
   ],
   "source": [
    "# Split df_inter and y into training and test sets\n",
    "# Set random_state to 1\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_inter, y, random_state=1)\n",
    "\n",
    "# Code for lasso with alpha from AIC\n",
    "lasso = Lasso(alpha=alpha_aic_)\n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "# Print R2 and MSE\n",
    "print(\"Training R2:\", lasso.score(X_train, y_train))\n",
    "print(\"Test R2:\", lasso.score(X_test, y_test))\n",
    "print(\"Training MSE:\", mean_squared_error(y_train, lasso.predict(X_train)))\n",
    "print(\"Test MSE:\", mean_squared_error(y_test, lasso.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training R2: 0.7968504776880992\n",
      "Test R2: 0.8729982805876442\n",
      "Training MSE: 16.124592079222325\n",
      "Test MSE: 12.580596464095665\n"
     ]
    }
   ],
   "source": [
    "# Code for lasso with alpha from BIC\n",
    "lasso = Lasso(alpha=alpha_bic_)\n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "# Print R2 and MSE\n",
    "print(\"Training R2:\", lasso.score(X_train, y_train))\n",
    "print(\"Test R2:\", lasso.score(X_test, y_test))\n",
    "print(\"Training MSE:\", mean_squared_error(y_train, lasso.predict(X_train)))\n",
    "print(\"Test MSE:\", mean_squared_error(y_test, lasso.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level up (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Lasso path\n",
    "\n",
    "From this section, you know that when using lasso, more parameters shrink to zero as your regularization parameter goes up. In Scikit-learn there is a function `lasso_path()` which visualizes the shrinkage of the coefficients while $alpha$ changes. Try this out yourself!\n",
    "\n",
    "https://scikit-learn.org/stable/auto_examples/linear_model/plot_lasso_coordinate_descent_path.html#sphx-glr-auto-examples-linear-model-plot-lasso-coordinate-descent-path-py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AIC and BIC for subset selection\n",
    "This notebook shows how you can use AIC and BIC purely for feature selection. Try this code out on our Boston housing data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://xavierbourretsicotte.github.io/subset_selection.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! You now know how to create better linear models and how to use AIC and BIC for both feature selection and to optimize your regularization parameter when performing Ridge and Lasso. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
